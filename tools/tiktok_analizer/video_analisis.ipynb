{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gola\n"
     ]
    }
   ],
   "source": [
    "print('gola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "\n",
    "# import speech_recognition as sr\n",
    "\n",
    "def analyze_video(video_path, output_dir=\"output\"):\n",
    "    \"\"\"\n",
    "    Analyze video file: extract frames, audio, and generate transcription\n",
    "    Parameters:\n",
    "        video_path (str): Path to the video file\n",
    "        output_dir (str): Directory to save extracted content\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    def extract_frames():\n",
    "        \"\"\"Extract frames from video and save key frames\"\"\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_count = 0\n",
    "        prev_frame = None\n",
    "        frame_exported_count = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Save frame if it's significantly different from previous frame\n",
    "            if prev_frame is not None:\n",
    "                diff = np.mean(np.abs(frame - prev_frame))\n",
    "                if diff > 135:  # Threshold for scene change\n",
    "                    frame_path = f\"{output_dir}/frame_{frame_count:04d}.jpg\"\n",
    "                    cv2.imwrite(frame_path, frame)\n",
    "                    frame_exported_count = frame_exported_count + 1\n",
    "            prev_frame = frame.copy()\n",
    "            frame_count += 1\n",
    "\n",
    "        cap.release()\n",
    "        print(f\"Total Extracted {frame_exported_count} frames\")\n",
    "        return frame_count\n",
    "\n",
    "    def extract_audio():\n",
    "        \"\"\"Extract audio from video and save as WAV with reduced size\"\"\"\n",
    "        video = VideoFileClip(video_path)\n",
    "        audio = video.audio\n",
    "\n",
    "        # Convert to mono and reduce sample rate\n",
    "        audio_path = f\"{output_dir}/audio.mp3\"  # Changed extension to .mp3\n",
    "        audio.write_audiofile(\n",
    "            audio_path,\n",
    "            fps=16000,  # Reduce sample rate from 44100 to 16000 Hz\n",
    "            nbytes=2,   # 16-bit depth instead of 32-bit\n",
    "            codec='libmp3lame',  # Use 16-bit PCM codec\n",
    "            ffmpeg_params=[\n",
    "                \"-ac\", \"1\",  # Convert to mono (1 channel)\n",
    "                \"-b:a\", \"64k\"    # Bitrate of 64kbps (you can adjust: 32k, 64k, 96k, 128k)\n",
    "            ]\n",
    "        )\n",
    "        video.close()\n",
    "        return audio_path\n",
    "\n",
    "    # def transcribe_audio(audio_path):\n",
    "    #     \"\"\"Generate transcription from audio file\"\"\"\n",
    "    #     recognizer = sr.Recognizer()\n",
    "\n",
    "    #     with sr.AudioFile(audio_path) as source:\n",
    "    #         audio = recognizer.record(source)\n",
    "\n",
    "    #     try:\n",
    "    #         transcription = recognizer.recognize_google(audio)\n",
    "\n",
    "    #         # Save transcription to file\n",
    "    #         with open(f\"{output_dir}/transcription.txt\", \"w\") as f:\n",
    "    #             f.write(transcription)\n",
    "\n",
    "    #         return transcription\n",
    "    #     except sr.UnknownValueError:\n",
    "    #         return \"Speech could not be understood\"\n",
    "    #     except sr.RequestError:\n",
    "    #         return \"Could not request results from speech recognition service\"\n",
    "\n",
    "    # Execute analysis\n",
    "    print(\"Extracting frames...\")\n",
    "    num_frames = extract_frames()\n",
    "    print(f\"Extracted {num_frames} frames\")\n",
    "\n",
    "    print(\"Extracting audio...\")\n",
    "    audio_path = extract_audio()\n",
    "    print(\"Audio extracted successfully\")\n",
    "\n",
    "    print(\"Generating transcription...\")\n",
    "    # transcription = transcribe_audio(audio_path)\n",
    "    print(\"Analysis complete!\")\n",
    "\n",
    "    return {\n",
    "        \"num_frames\": num_frames,\n",
    "        \"audio_path\": audio_path,\n",
    "        # \"transcription\": transcription\n",
    "    }\n",
    "\n",
    "# Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames...\n",
      "Total Extracted 6 frames\n",
      "Extracted 1198 frames\n",
      "Extracting audio...\n",
      "MoviePy - Writing audio in output/audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Audio extracted successfully\n",
      "Generating transcription...\n",
      "Analysis complete!\n",
      "Processed 1198 frames\n",
      "Audio saved to: output/audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "video_path = \"MyVideo.mp4\"\n",
    "results = analyze_video(video_path)\n",
    "print(f\"Processed {results['num_frames']} frames\")\n",
    "print(f\"Audio saved to: {results['audio_path']}\")\n",
    "# print(f\"Transcription: {results['transcription'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/audio.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m audio_file\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput/audio.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      7\u001b[0m transcription \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mtranscriptions\u001b[38;5;241m.\u001b[39mcreate( model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhisper-1\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39maudio_file, response_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose_json\u001b[39m\u001b[38;5;124m'\u001b[39m,timestamp_granularities\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/dataclouder-template-python-fMsF7t-R-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/audio.wav'"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "audio_file= open(\"output/audio.wav\", \"rb\")\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "transcription = client.audio.transcriptions.create( model=\"whisper-1\", file=audio_file, response_format='verbose_json',timestamp_granularities=['word'])\n",
    "print(transcription.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataclouder-template-python-fMsF7t-R-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
